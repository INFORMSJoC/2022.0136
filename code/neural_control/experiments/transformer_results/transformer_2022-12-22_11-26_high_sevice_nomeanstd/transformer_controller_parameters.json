{
    "input_hidden_layer_sizes": [
        16,
        16,
        16
    ],
    "n_input_features": 3,
    "num_decoder_layers": 1,
    "num_encoder_layers": 1,
    "output_hidden_layer_sizes": [
        16
    ],
    "transformer_activation": "torch.nn.functional.relu",
    "transformer_dropout": 0.0,
    "transformer_heads": 8,
    "transformer_hidden_dimensions": 64
}